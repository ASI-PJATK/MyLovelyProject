Metadata-Version: 2.1
Name: kedro
Version: 0.18.14
Summary: Kedro helps you build production-ready data and analytics pipelines
Author: Kedro
License: Apache Software License (Apache 2.0)
Project-URL: Homepage, https://kedro.org
Project-URL: Source, https://github.com/kedro-org/kedro
Project-URL: Documentation, https://docs.kedro.org
Project-URL: Tracker, https://github.com/kedro-org/kedro/issues
Keywords: pipelines,machine learning,data pipelines,data science,data engineering
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: anyconfig >=0.10.0
Requires-Dist: attrs >=21.3
Requires-Dist: build >=0.7.0
Requires-Dist: cachetools >=4.1
Requires-Dist: click >=4.0
Requires-Dist: cookiecutter <3.0,>=2.1.1
Requires-Dist: dynaconf <4.0,>=3.1.2
Requires-Dist: fsspec >=2021.4
Requires-Dist: gitpython >=3.0
Requires-Dist: importlib-resources <7.0,>=1.3
Requires-Dist: jmespath >=0.9.5
Requires-Dist: more-itertools >=8.14.0
Requires-Dist: omegaconf >=2.1.1
Requires-Dist: parse >=1.19.0
Requires-Dist: pip-tools >=6.5
Requires-Dist: pluggy <1.3,>=1.0
Requires-Dist: PyYAML <7.0,>=4.2
Requires-Dist: rich <14.0,>=12.0
Requires-Dist: rope <2.0,>=0.21
Requires-Dist: setuptools >=65.5.1
Requires-Dist: toml >=0.10.0
Requires-Dist: toposort >=1.5
Requires-Dist: importlib-metadata <5.0,>=3.6 ; python_version < "3.8"
Requires-Dist: importlib-metadata <7.0,>=3.6 ; python_version >= "3.8"
Provides-Extra: all
Requires-Dist: Jinja2 <3.1.0 ; extra == 'all'
Requires-Dist: Pillow ~=9.0 ; extra == 'all'
Requires-Dist: PyYAML <7.0,>=4.2 ; extra == 'all'
Requires-Dist: SQLAlchemy ~=1.2 ; extra == 'all'
Requires-Dist: biopython ~=1.73 ; extra == 'all'
Requires-Dist: compress-pickle[lz4] ~=2.1.0 ; extra == 'all'
Requires-Dist: dask[complete] ~=2021.10 ; extra == 'all'
Requires-Dist: delta-spark <3.0,>=1.0 ; extra == 'all'
Requires-Dist: docutils ==0.16 ; extra == 'all'
Requires-Dist: geopandas <1.0,>=0.6.0 ; extra == 'all'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'all'
Requires-Dist: holoviews >=1.13.0 ; extra == 'all'
Requires-Dist: ipykernel <7.0,>=5.3 ; extra == 'all'
Requires-Dist: kedro-datasets[all] ~=1.7.0 ; extra == 'all'
Requires-Dist: lxml ~=4.6 ; extra == 'all'
Requires-Dist: matplotlib <4.0,>=3.0.3 ; extra == 'all'
Requires-Dist: myst-parser ~=1.0.0 ; extra == 'all'
Requires-Dist: networkx ~=2.4 ; extra == 'all'
Requires-Dist: opencv-python ~=4.5.5.64 ; extra == 'all'
Requires-Dist: openpyxl <4.0,>=3.0.6 ; extra == 'all'
Requires-Dist: pandas-gbq <0.18.0,>=0.12.0 ; extra == 'all'
Requires-Dist: pandas ~=1.3 ; extra == 'all'
Requires-Dist: plotly <6.0,>=4.8.0 ; extra == 'all'
Requires-Dist: pyarrow <7.0,>=1.0 ; extra == 'all'
Requires-Dist: pyproj ~=3.0 ; extra == 'all'
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'all'
Requires-Dist: redis ~=4.1 ; extra == 'all'
Requires-Dist: requests ~=2.20 ; extra == 'all'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'all'
Requires-Dist: scikit-learn ~=1.0.2 ; extra == 'all'
Requires-Dist: scipy ~=1.7.3 ; extra == 'all'
Requires-Dist: sphinx-autodoc-typehints ==1.20.2 ; extra == 'all'
Requires-Dist: sphinx-notfound-page ; extra == 'all'
Requires-Dist: sphinx-copybutton ==0.3.1 ; extra == 'all'
Requires-Dist: sphinx-rtd-theme ==1.2.0 ; extra == 'all'
Requires-Dist: sphinxcontrib-mermaid ~=0.7.1 ; extra == 'all'
Requires-Dist: sphinx ~=5.3.0 ; extra == 'all'
Requires-Dist: triad <1.0,>=0.6.7 ; extra == 'all'
Requires-Dist: tensorflow ~=2.0 ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'all'
Requires-Dist: tables ~=3.6 ; (platform_system != "Windows") and extra == 'all'
Requires-Dist: tensorflow-macos ~=2.0 ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'all'
Requires-Dist: tables ~=3.6.0 ; (platform_system == "Windows") and extra == 'all'
Provides-Extra: api
Requires-Dist: requests ~=2.20 ; extra == 'api'
Provides-Extra: api.apidataset
Requires-Dist: requests ~=2.20 ; extra == 'api.apidataset'
Provides-Extra: biosequence
Requires-Dist: biopython ~=1.73 ; extra == 'biosequence'
Provides-Extra: biosequence.biosequencedataset
Requires-Dist: biopython ~=1.73 ; extra == 'biosequence.biosequencedataset'
Provides-Extra: dask
Requires-Dist: dask[complete] ~=2021.10 ; extra == 'dask'
Requires-Dist: triad <1.0,>=0.6.7 ; extra == 'dask'
Provides-Extra: dask.parquetdataset
Requires-Dist: dask[complete] ~=2021.10 ; extra == 'dask.parquetdataset'
Requires-Dist: triad <1.0,>=0.6.7 ; extra == 'dask.parquetdataset'
Provides-Extra: docs
Requires-Dist: docutils ==0.16 ; extra == 'docs'
Requires-Dist: sphinx ~=5.3.0 ; extra == 'docs'
Requires-Dist: sphinx-rtd-theme ==1.2.0 ; extra == 'docs'
Requires-Dist: sphinx-autodoc-typehints ==1.20.2 ; extra == 'docs'
Requires-Dist: sphinx-copybutton ==0.3.1 ; extra == 'docs'
Requires-Dist: sphinx-notfound-page ; extra == 'docs'
Requires-Dist: ipykernel <7.0,>=5.3 ; extra == 'docs'
Requires-Dist: sphinxcontrib-mermaid ~=0.7.1 ; extra == 'docs'
Requires-Dist: myst-parser ~=1.0.0 ; extra == 'docs'
Requires-Dist: Jinja2 <3.1.0 ; extra == 'docs'
Requires-Dist: kedro-datasets[all] ~=1.7.0 ; extra == 'docs'
Provides-Extra: geopandas
Requires-Dist: geopandas <1.0,>=0.6.0 ; extra == 'geopandas'
Requires-Dist: pyproj ~=3.0 ; extra == 'geopandas'
Provides-Extra: geopandas.geojsondataset
Requires-Dist: geopandas <1.0,>=0.6.0 ; extra == 'geopandas.geojsondataset'
Requires-Dist: pyproj ~=3.0 ; extra == 'geopandas.geojsondataset'
Provides-Extra: holoviews
Requires-Dist: holoviews >=1.13.0 ; extra == 'holoviews'
Provides-Extra: holoviews.holoviewswriter
Requires-Dist: holoviews >=1.13.0 ; extra == 'holoviews.holoviewswriter'
Provides-Extra: matplotlib
Requires-Dist: matplotlib <4.0,>=3.0.3 ; extra == 'matplotlib'
Provides-Extra: matplotlib.matplotlibwriter
Requires-Dist: matplotlib <4.0,>=3.0.3 ; extra == 'matplotlib.matplotlibwriter'
Provides-Extra: networkx
Requires-Dist: networkx ~=2.4 ; extra == 'networkx'
Provides-Extra: networkx.networkxdataset
Requires-Dist: networkx ~=2.4 ; extra == 'networkx.networkxdataset'
Provides-Extra: pandas
Requires-Dist: SQLAlchemy ~=1.2 ; extra == 'pandas'
Requires-Dist: lxml ~=4.6 ; extra == 'pandas'
Requires-Dist: openpyxl <4.0,>=3.0.6 ; extra == 'pandas'
Requires-Dist: pandas-gbq <0.18.0,>=0.12.0 ; extra == 'pandas'
Requires-Dist: pandas ~=1.3 ; extra == 'pandas'
Requires-Dist: pyarrow <7.0,>=1.0 ; extra == 'pandas'
Provides-Extra: pandas.csvdataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.csvdataset'
Provides-Extra: pandas.exceldataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.exceldataset'
Requires-Dist: openpyxl <4.0,>=3.0.6 ; extra == 'pandas.exceldataset'
Provides-Extra: pandas.featherdataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.featherdataset'
Provides-Extra: pandas.gbqquerydataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.gbqquerydataset'
Requires-Dist: pandas-gbq <0.18.0,>=0.12.0 ; extra == 'pandas.gbqquerydataset'
Provides-Extra: pandas.gbqtabledataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.gbqtabledataset'
Requires-Dist: pandas-gbq <0.18.0,>=0.12.0 ; extra == 'pandas.gbqtabledataset'
Provides-Extra: pandas.genericdataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.genericdataset'
Provides-Extra: pandas.hdfdataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.hdfdataset'
Requires-Dist: tables ~=3.6 ; (platform_system != "Windows") and extra == 'pandas.hdfdataset'
Requires-Dist: tables ~=3.6.0 ; (platform_system == "Windows") and extra == 'pandas.hdfdataset'
Provides-Extra: pandas.jsondataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.jsondataset'
Provides-Extra: pandas.parquetdataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.parquetdataset'
Requires-Dist: pyarrow <7.0,>=1.0 ; extra == 'pandas.parquetdataset'
Provides-Extra: pandas.sqlquerydataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.sqlquerydataset'
Requires-Dist: SQLAlchemy ~=1.2 ; extra == 'pandas.sqlquerydataset'
Provides-Extra: pandas.sqltabledataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.sqltabledataset'
Requires-Dist: SQLAlchemy ~=1.2 ; extra == 'pandas.sqltabledataset'
Provides-Extra: pandas.xmldataset
Requires-Dist: pandas ~=1.3 ; extra == 'pandas.xmldataset'
Requires-Dist: lxml ~=4.6 ; extra == 'pandas.xmldataset'
Requires-Dist: tables ~=3.6 ; (platform_system != "Windows") and extra == 'pandas'
Requires-Dist: tables ~=3.6.0 ; (platform_system == "Windows") and extra == 'pandas'
Provides-Extra: pickle
Requires-Dist: compress-pickle[lz4] ~=2.1.0 ; extra == 'pickle'
Provides-Extra: pickle.pickledataset
Requires-Dist: compress-pickle[lz4] ~=2.1.0 ; extra == 'pickle.pickledataset'
Provides-Extra: pillow
Requires-Dist: Pillow ~=9.0 ; extra == 'pillow'
Provides-Extra: pillow.imagedataset
Requires-Dist: Pillow ~=9.0 ; extra == 'pillow.imagedataset'
Provides-Extra: plotly
Requires-Dist: pandas ~=1.3 ; extra == 'plotly'
Requires-Dist: plotly <6.0,>=4.8.0 ; extra == 'plotly'
Provides-Extra: plotly.jsondataset
Requires-Dist: plotly <6.0,>=4.8.0 ; extra == 'plotly.jsondataset'
Provides-Extra: plotly.plotlydataset
Requires-Dist: pandas ~=1.3 ; extra == 'plotly.plotlydataset'
Requires-Dist: plotly <6.0,>=4.8.0 ; extra == 'plotly.plotlydataset'
Provides-Extra: redis
Requires-Dist: redis ~=4.1 ; extra == 'redis'
Provides-Extra: spark
Requires-Dist: delta-spark <3.0,>=1.0 ; extra == 'spark'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'spark'
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'spark'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'spark'
Provides-Extra: spark.deltatabledataset
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'spark.deltatabledataset'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'spark.deltatabledataset'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'spark.deltatabledataset'
Requires-Dist: delta-spark <3.0,>=1.0 ; extra == 'spark.deltatabledataset'
Provides-Extra: spark.sparkdataset
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'spark.sparkdataset'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'spark.sparkdataset'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'spark.sparkdataset'
Provides-Extra: spark.sparkhivedataset
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'spark.sparkhivedataset'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'spark.sparkhivedataset'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'spark.sparkhivedataset'
Provides-Extra: spark.sparkjdbcdataset
Requires-Dist: pyspark <3.4,>=2.2 ; extra == 'spark.sparkjdbcdataset'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'spark.sparkjdbcdataset'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'spark.sparkjdbcdataset'
Provides-Extra: svmlight
Requires-Dist: scikit-learn ~=1.0.2 ; extra == 'svmlight'
Requires-Dist: scipy ~=1.7.3 ; extra == 'svmlight'
Provides-Extra: svmlight.svmlightdataset
Requires-Dist: scikit-learn ~=1.0.2 ; extra == 'svmlight.svmlightdataset'
Requires-Dist: scipy ~=1.7.3 ; extra == 'svmlight.svmlightdataset'
Provides-Extra: tensorflow
Provides-Extra: tensorflow.tensorflowmodeldataset
Requires-Dist: tensorflow ~=2.0 ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'tensorflow.tensorflowmodeldataset'
Requires-Dist: tensorflow-macos ~=2.0 ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'tensorflow.tensorflowmodeldataset'
Requires-Dist: tensorflow ~=2.0 ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'tensorflow'
Requires-Dist: tensorflow-macos ~=2.0 ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'tensorflow'
Provides-Extra: test
Requires-Dist: bandit <2.0,>=1.6.2 ; extra == 'test'
Requires-Dist: behave ==1.2.6 ; extra == 'test'
Requires-Dist: biopython ~=1.73 ; extra == 'test'
Requires-Dist: blacken-docs ==1.9.2 ; extra == 'test'
Requires-Dist: black ~=22.0 ; extra == 'test'
Requires-Dist: compress-pickle[lz4] ~=2.1.0 ; extra == 'test'
Requires-Dist: coverage[toml] ; extra == 'test'
Requires-Dist: dask[complete] ~=2021.10 ; extra == 'test'
Requires-Dist: dill ~=0.3.1 ; extra == 'test'
Requires-Dist: filelock <4.0,>=3.4.0 ; extra == 'test'
Requires-Dist: geopandas <1.0,>=0.6.0 ; extra == 'test'
Requires-Dist: hdfs <3.0,>=2.5.8 ; extra == 'test'
Requires-Dist: holoviews >=1.13.0 ; extra == 'test'
Requires-Dist: import-linter[toml] ==1.8.0 ; extra == 'test'
Requires-Dist: isort ~=5.0 ; extra == 'test'
Requires-Dist: Jinja2 <3.1.0 ; extra == 'test'
Requires-Dist: joblib >=0.14 ; extra == 'test'
Requires-Dist: jupyterlab-server <2.16.0,>=2.11.1 ; extra == 'test'
Requires-Dist: jupyterlab <3.6.0,~=3.0 ; extra == 'test'
Requires-Dist: jupyter ~=1.0 ; extra == 'test'
Requires-Dist: lxml ~=4.6 ; extra == 'test'
Requires-Dist: memory-profiler <1.0,>=0.50.0 ; extra == 'test'
Requires-Dist: networkx ~=2.4 ; extra == 'test'
Requires-Dist: opencv-python ~=4.5.5.64 ; extra == 'test'
Requires-Dist: openpyxl <4.0,>=3.0.3 ; extra == 'test'
Requires-Dist: pandas ~=1.3 ; extra == 'test'
Requires-Dist: Pillow ~=9.0 ; extra == 'test'
Requires-Dist: plotly <6.0,>=4.8.0 ; extra == 'test'
Requires-Dist: pre-commit <3.0,>=2.9.2 ; extra == 'test'
Requires-Dist: pylint <3.0,>=2.17.0 ; extra == 'test'
Requires-Dist: pyproj ~=3.0 ; extra == 'test'
Requires-Dist: pytest-cov ~=3.0 ; extra == 'test'
Requires-Dist: pytest-mock <2.0,>=1.7.1 ; extra == 'test'
Requires-Dist: pytest-xdist[psutil] ~=2.2.1 ; extra == 'test'
Requires-Dist: pytest ~=7.2 ; extra == 'test'
Requires-Dist: redis ~=4.1 ; extra == 'test'
Requires-Dist: requests-mock ~=1.6 ; extra == 'test'
Requires-Dist: requests ~=2.20 ; extra == 'test'
Requires-Dist: s3fs <0.5,>=0.3.0 ; extra == 'test'
Requires-Dist: scikit-learn <2,>=1.0.2 ; extra == 'test'
Requires-Dist: scipy >=1.7.3 ; extra == 'test'
Requires-Dist: semver ; extra == 'test'
Requires-Dist: SQLAlchemy ~=1.2 ; extra == 'test'
Requires-Dist: triad <1.0,>=0.6.7 ; extra == 'test'
Requires-Dist: trufflehog ~=2.1 ; extra == 'test'
Requires-Dist: xlsxwriter ~=1.0 ; extra == 'test'
Requires-Dist: tensorflow ~=2.0 ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'test'
Requires-Dist: tables <3.9.0,~=3.6 ; (platform_system != "Windows") and extra == 'test'
Requires-Dist: tensorflow-macos ~=2.0 ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'test'
Requires-Dist: tables ~=3.6.0 ; (platform_system == "Windows" and python_version < "3.8") and extra == 'test'
Requires-Dist: tables ~=3.8.0 ; (platform_system == "Windows" and python_version >= "3.8") and extra == 'test'
Requires-Dist: matplotlib <3.4,>=3.0.3 ; (python_version < "3.10") and extra == 'test'
Requires-Dist: moto ==1.3.7 ; (python_version < "3.10") and extra == 'test'
Requires-Dist: delta-spark ~=1.2.1 ; (python_version < "3.11") and extra == 'test'
Requires-Dist: pandas-gbq <0.18.0,>=0.12.0 ; (python_version < "3.11") and extra == 'test'
Requires-Dist: pyarrow >=1.0 ; (python_version < "3.11") and extra == 'test'
Requires-Dist: pyspark <3.4,>=2.2 ; (python_version < "3.11") and extra == 'test'
Requires-Dist: ipython <8.0,>=7.31.1 ; (python_version < "3.8") and extra == 'test'
Requires-Dist: adlfs <=2022.2,>=2021.7.1 ; (python_version == "3.7") and extra == 'test'
Requires-Dist: gcsfs <=2023.1,>=2021.4 ; (python_version == "3.7") and extra == 'test'
Requires-Dist: matplotlib <3.6,>=3.5 ; (python_version >= "3.10") and extra == 'test'
Requires-Dist: moto ==4.1.12 ; (python_version >= "3.10") and extra == 'test'
Requires-Dist: delta-spark >=1.2.1 ; (python_version >= "3.11") and extra == 'test'
Requires-Dist: pandas-gbq >=0.18.0 ; (python_version >= "3.11") and extra == 'test'
Requires-Dist: pyarrow >=7.0 ; (python_version >= "3.11") and extra == 'test'
Requires-Dist: pyspark >=3.4 ; (python_version >= "3.11") and extra == 'test'
Requires-Dist: adlfs ~=2023.1 ; (python_version >= "3.8") and extra == 'test'
Requires-Dist: gcsfs <2023.3,>=2023.1 ; (python_version >= "3.8") and extra == 'test'
Requires-Dist: ipython ~=8.10 ; (python_version >= "3.8") and extra == 'test'
Provides-Extra: video
Requires-Dist: opencv-python ~=4.5.5.64 ; extra == 'video'
Provides-Extra: video.videodataset
Requires-Dist: opencv-python ~=4.5.5.64 ; extra == 'video.videodataset'
Provides-Extra: yaml
Requires-Dist: PyYAML <7.0,>=4.2 ; extra == 'yaml'
Requires-Dist: pandas ~=1.3 ; extra == 'yaml'
Provides-Extra: yaml.yamldataset
Requires-Dist: pandas ~=1.3 ; extra == 'yaml.yamldataset'
Requires-Dist: PyYAML <7.0,>=4.2 ; extra == 'yaml.yamldataset'

![Kedro Logo Banner - Light](https://raw.githubusercontent.com/kedro-org/kedro/main/.github/demo-dark.png#gh-dark-mode-only)
![Kedro Logo Banner - Dark](https://raw.githubusercontent.com/kedro-org/kedro/main/.github/demo-light.png#gh-light-mode-only)
[![Python version](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue.svg)](https://pypi.org/project/kedro/)
[![PyPI version](https://badge.fury.io/py/kedro.svg)](https://pypi.org/project/kedro/)
[![Conda version](https://img.shields.io/conda/vn/conda-forge/kedro.svg)](https://anaconda.org/conda-forge/kedro)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/kedro-org/kedro/blob/main/LICENSE.md)
[![Slack Organisation](https://img.shields.io/badge/slack-chat-blueviolet.svg?label=Kedro%20Slack&logo=slack)](https://slack.kedro.org)
[![Slack Archive](https://img.shields.io/badge/slack-archive-blueviolet.svg?label=Kedro%20Slack%20)](https://linen-slack.kedro.org/)
![CircleCI - Main Branch](https://img.shields.io/circleci/build/github/kedro-org/kedro/main?label=main)
![Develop Branch Build](https://img.shields.io/circleci/build/github/kedro-org/kedro/develop?label=develop)
[![Documentation](https://readthedocs.org/projects/kedro/badge/?version=stable)](https://docs.kedro.org/)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6711/badge)](https://bestpractices.coreinfrastructure.org/projects/6711)
[![Monthly downloads](https://static.pepy.tech/badge/kedro/month)](https://pepy.tech/project/kedro)
[![Total downloads](https://static.pepy.tech/badge/kedro)](https://pepy.tech/project/kedro)

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

## What is Kedro?

Kedro is a toolbox for production-ready data science. It uses software engineering best practices to help you create data engineering and data science pipelines that are reproducible, maintainable, and modular. You can find out more at [kedro.org](https://kedro.org).

Kedro is an open-source Python framework hosted by the [LF AI & Data Foundation](https://lfaidata.foundation/).

## How do I install Kedro?

To install Kedro from the Python Package Index (PyPI) run:

```
pip install kedro
```

It is also possible to install Kedro using `conda`:

```
conda install -c conda-forge kedro
```

Our [Get Started guide](https://docs.kedro.org/en/stable/get_started/install.html) contains full installation instructions, and includes how to set up Python virtual environments.

## What are the main features of Kedro?

| Feature              | What is this?                                                                                                                                                                                                                                                                                                                                                                                  |
| -------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Project Template     | A standard, modifiable and easy-to-use project template based on [Cookiecutter Data Science](https://github.com/drivendata/cookiecutter-data-science/).                                                                                                                                                                                                                                        |
| Data Catalog         | A series of lightweight data connectors used to save and load data across many different file formats and file systems, including local and network file systems, cloud object stores, and HDFS. The Data Catalog also includes data and model versioning for file-based systems.                                                                                                              |
| Pipeline Abstraction | Automatic resolution of dependencies between pure Python functions and data pipeline visualisation using [Kedro-Viz](https://github.com/kedro-org/kedro-viz).                                                                                                                                                                                                                                  |
| Coding Standards     | Test-driven development using [`pytest`](https://github.com/pytest-dev/pytest), produce well-documented code using [Sphinx](http://www.sphinx-doc.org/en/master/), create linted code with support for [`flake8`](https://github.com/PyCQA/flake8), [`isort`](https://github.com/PyCQA/isort) and [`black`](https://github.com/psf/black) and make use of the standard Python logging library. |
| Flexible Deployment  | Deployment strategies that include single or distributed-machine deployment as well as additional support for deploying on Argo, Prefect, Kubeflow, AWS Batch and Databricks.                                                                                                                                                                                                                  |

## How do I use Kedro?

The [Kedro documentation](https://docs.kedro.org/en/stable/) first explains [how to install Kedro](https://docs.kedro.org/en/stable/get_started/install.html) and then introduces [key Kedro concepts](https://docs.kedro.org/en/stable/get_started/kedro_concepts.html).

You can then review the [spaceflights tutorial](https://docs.kedro.org/en/stable/tutorial/spaceflights_tutorial.html) to build a Kedro project for hands-on experience

For new and intermediate Kedro users, there's a comprehensive section on [how to visualise Kedro projects using Kedro-Viz](https://docs.kedro.org/en/stable/visualisation/index.html).


<p align="center">
    <img src="https://raw.githubusercontent.com/kedro-org/kedro-viz/main/.github/img/banner.png" alt>
    <em>A pipeline visualisation generated using Kedro-Viz</em>
</p>

Additional documentation explains [how to work with Kedro and Jupyter notebooks](https://docs.kedro.org/en/stable/notebooks_and_ipython/index.html), and there are a set of advanced user guides for advanced for key Kedro features. We also recommend the [API reference documentation](/kedro) for further information.


## Why does Kedro exist?

Kedro is built upon our collective best-practice (and mistakes) trying to deliver real-world ML applications that have vast amounts of raw unvetted data. We developed Kedro to achieve the following:

- To address the main shortcomings of Jupyter notebooks, one-off scripts, and glue-code because there is a focus on
  creating **maintainable data science code**
- To enhance **team collaboration** when different team members have varied exposure to software engineering concepts
- To increase efficiency, because applied concepts like modularity and separation of concerns inspire the creation of
  **reusable analytics code**

Find out more about how Kedro can answer your use cases from the [product FAQs on the Kedro website](https://kedro.org/#faq).

## The humans behind Kedro

The [Kedro product team](https://docs.kedro.org/en/stable/contribution/technical_steering_committee.html#kedro-maintainers) and a number of [open source contributors from across the world](https://github.com/kedro-org/kedro/releases) maintain Kedro.

## Can I contribute?

Yes! We welcome all kinds of contributions. Check out our [guide to contributing to Kedro](https://github.com/kedro-org/kedro/wiki/Contribute-to-Kedro).

## Where can I learn more?

There is a growing community around Kedro. We encourage you to ask and answer technical questions on [Slack](https://slack.kedro.org/) and bookmark the [Linen archive of past discussions](https://linen-slack.kedro.org/).

We keep a list of [technical FAQs in the Kedro documentation](https://docs.kedro.org/en/stable/faq/faq.html) and you can find a  growing list of blog posts, videos and projects that use Kedro over on the [`awesome-kedro` GitHub repository](https://github.com/kedro-org/awesome-kedro). If you have created anything with Kedro we'd love to include it on the list. Just make a PR to add it!

## How can I cite Kedro?

If you're an academic, Kedro can also help you, for example, as a tool to solve the problem of reproducible research. Use the "Cite this repository" button on [our repository](https://github.com/kedro-org/kedro) to generate a citation from the [CITATION.cff file](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files).
